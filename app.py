import streamlit as st
from PIL import Image
import io
import base64
import pandas as pd
from docx import Document
# Importa la librer铆a de Vertex AI
import vertexai
from vertexai.generative_models import GenerativeModel, Part, Image as VertexImage

# --- Configuraci贸n de Google Cloud (hacer al inicio) ---
# vertexai.init(project="tu-proyecto-gcp", location="tu-region")

# --- Funci贸n Placeholder para llamar a Vertex AI ---
# Esta es la funci贸n central (Punto 4)
def generar_item_espejo(imagen_cargada, taxonomia, contexto_adicional):
    """
    Llama a Vertex AI (Gemini) para analizar la imagen y el texto
    y generar el nuevo 铆tem y las justificaciones.
    """
    
    # 1. Inicializar el modelo multimodal (ej. Gemini 1.5 Pro)
    model = GenerativeModel("gemini-2.5-flash-lite") 

    # 2. Cargar la imagen y convertirla para la API
    # imagen_cargada es el objeto de st.file_uploader
    img_pil = Image.open(imagen_cargada)
    
    # Convertir PIL Image a bytes
    buffered = io.BytesIO()
    img_pil.save(buffered, format="PNG")
    img_bytes = buffered.getvalue()

    # Crear el objeto de imagen para Vertex AI
    vertex_img = VertexImage.from_bytes(img_bytes)

    # 3. Dise帽o del Prompt (La parte m谩s importante)
    # Aqu铆 integramos la idea de "Shells Cognitivos"
    prompt_texto = f"""
    Eres un experto en psicometr铆a y dise帽o de 铆tems educativos.
    Tu tarea es analizar una pregunta de selecci贸n m煤ltiple (presentada como imagen)
    y generar una "pregunta espejo" basada en el concepto de 'shell cognitivo' de Shavelson.

    **Shell Cognitivo (Pregunta Original):**
    Analiza la estructura l贸gica, el tipo de habilidad cognitiva evaluada y el formato
    de la pregunta en la imagen adjunta.

    **Taxonom铆a Requerida:**
    La nueva pregunta debe alinearse con esta taxonom铆a: {taxonomia}

    **Contexto Adicional del Usuario:**
    {contexto_adicional}

    **Instrucciones de Generaci贸n:**

    1.  **Generar Pregunta Espejo (Punto 4.1):**
        Crea una nueva pregunta que mantenga la misma estructura cognitiva (el 'shell')
        que la pregunta original, pero utiliza un contenido tem谩tico diferente.
        Aseg煤rate de que la dificultad y la habilidad medida sean equivalentes.
        Presenta la pregunta completa con sus opciones (A, B, C, D...).

    2.  **Descripci贸n de Imagen (Punto 4.2):**
        Si la pregunta original usaba una imagen, genera una descripci贸n textual 
        detallada de esa imagen y describe qu茅 tipo de imagen se necesitar铆a
        para la nueva "pregunta espejo" (si aplica). Si no hay imagen, indica "N/A".

    3.  **Justificaciones (Punto 4.3):**
        Para la NUEVA pregunta espejo que generaste:
        * Identifica la clave (respuesta correcta).
        * Escribe una justificaci贸n detallada de por qu茅 la clave es correcta.
        * Escribe justificaciones detalladas para CADA una de las opciones no v谩lidas
            (distractores), explicando el error conceptual que representa cada una.

    **Formato de Salida (JSON):**
    Responde NICAMENTE con un objeto JSON v谩lido con la siguiente estructura:
    {{
      "pregunta_espejo": "Texto completo de la nueva pregunta...",
      "opciones": {{
        "A": "Texto de la opci贸n A",
        "B": "Texto de la opci贸n B",
        "C": "Texto de la opci贸n C",
        "D": "Texto de la opci贸n D"
      }},
      "clave": "A",
      "descripcion_imagen_original": "Descripci贸n de la imagen en la pregunta de entrada...",
      "justificacion_clave": "Raz贸n por la que la clave es correcta...",
      "justificaciones_distractores": [
        {{ "opcion": "A", "justificacion": "Por qu茅 A es incorrecta..." }},
        {{ "opcion": "B", "justificacion": "Por qu茅 B es incorrecta..." }},
        {{ "opcion": "C", "justificacion": "Por qu茅 C es incorrecta..." }},
        {{ "opcion": "D", "justificacion": "Por qu茅 D es incorrecta..." }}
      ]
    }}
    """

    # 4. Realizar la llamada multimodal
    st.info("Generando 铆tem... esto puede tardar un momento.")
    
    try:
        # Combinar la imagen y el prompt de texto
        response = model.generate_content([vertex_img, prompt_texto])
        
        # Asumiendo que la respuesta es un JSON como se solicit贸
        # Es crucial limpiar el 'markdown' que a veces a帽ade el modelo
        respuesta_texto = response.text.strip().replace("```json", "").replace("```", "")
        
        # Aqu铆 deber铆as parsear el JSON (import json)
        # Por simplicidad, aqu铆 solo devolvemos el texto
        return respuesta_texto 

    except Exception as e:
        st.error(f"Error al contactar Vertex AI: {e}")
        return None

# --- Funciones de Exportaci贸n (Punto 5) ---

def crear_excel(datos_generados):
    # Aqu铆 'datos_generados' deber铆a ser el JSON parseado
    # Esto es un ejemplo simplificado
    df = pd.DataFrame({
        'Componente': ['Pregunta Espejo', 'Clave', 'Justificaci贸n Clave'],
        'Contenido': [
            datos_generados.get("pregunta_espejo", ""),
            datos_generados.get("clave", ""),
            datos_generados.get("justificacion_clave", "")
        ]
    })
    
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Item Generado')
    
    return output.getvalue()

def crear_word(datos_generados):
    # Aqu铆 'datos_generados' deber铆a ser el JSON parseado
    document = Document()
    document.add_heading('tem Espejo Generado', level=1)
    
    document.add_heading('Pregunta Espejo', level=2)
    document.add_paragraph(datos_generados.get("pregunta_espejo", "N/A"))
    
    document.add_heading('Opciones', level=3)
    opciones = datos_generados.get("opciones", {})
    for letra, texto in opciones.items():
        document.add_paragraph(f"**{letra}:** {texto}")

    document.add_heading('Justificaciones', level=2)
    document.add_paragraph(f"**Clave:** {datos_generados.get('clave', 'N/A')}")
    document.add_paragraph(f"**Justificaci贸n de la Clave:** {datos_generados.get('justificacion_clave', 'N/A')}")
    
    output = io.BytesIO()
    document.save(output)
    return output.getvalue()

# --- Interfaz de Streamlit ---

st.set_page_config(layout="wide")
st.title(" Generador de tems Espejo (Basado en Shells Cognitivos)")

# --- Columnas para la entrada ---
col1, col2 = st.columns(2)

with col1:
    st.header("1. Cargar tem Original")
    # (Punto 1)
    imagen_subida = st.file_uploader(
        "Sube el pantallazo de la pregunta", 
        type=["png", "jpg", "jpeg"]
    )
    
    if imagen_subida:
        st.image(imagen_subida, caption="tem cargado", use_column_width=True)

with col2:
    st.header("2. Configurar Generaci贸n")
    
    # (Punto 2)
    # Debes pre-cargar tu lista de taxonom铆as
    TAXONOMIAS_PRECARGADAS = [
        "Recordar (Bloom)",
        "Comprender (Bloom)",
        "Aplicar (Bloom)",
        "Analizar (Bloom)",
        "Evaluar (Bloom)",
        "Crear (Bloom)",
        "Otro Nivel Taxon贸mico"
    ]
    taxonomia_sel = st.selectbox(
        "Selecciona la taxonom铆a del 铆tem", 
        options=TAXONOMIAS_PRECARGADAS
    )
    
    # (Punto 3)
    info_adicional = st.text_area(
        "Informaci贸n adicional (ej. tema espec铆fico, contexto)",
        height=150,
        placeholder="Ej: 'Usar el tema de fotos铆ntesis', 'Enfocar en estudiantes de grado 10'"
    )

# --- Bot贸n de Generaci贸n ---
st.divider()
if st.button(" Generar tem Espejo", use_container_width=True, type="primary"):
    if imagen_subida is not None:
        # (Punto 4)
        # Aqu铆 se llama a la funci贸n de Vertex AI
        resultado_generado = generar_item_espejo(
            imagen_subida, 
            taxonomia_sel, 
            info_adicional
        )
        
        if resultado_generado:
            st.success("隆tem generado con 茅xito!")
            # Guardamos el resultado en el estado de la sesi贸n
            # Asumiendo que 'resultado_generado' es el texto JSON
            # En un caso real, aqu铆 deber铆as parsear el JSON
            st.session_state['resultado_json_texto'] = resultado_generado
            st.session_state['resultado_json_obj'] = pd.io.json.loads(resultado_generado) # Parsear
            
            # Mostrar la salida
            st.json(st.session_state['resultado_json_obj'])

    else:
        st.warning("Por favor, sube una imagen primero.")

# --- Secci贸n de Descarga (Punto 5) ---
if 'resultado_json_obj' in st.session_state:
    st.divider()
    st.header("3. Descargar Resultados")
    
    datos_obj = st.session_state['resultado_json_obj']
    
    col_word, col_excel = st.columns(2)
    
    with col_word:
        archivo_word = crear_word(datos_obj)
        st.download_button(
            label="Descargar en Word (.docx)",
            data=archivo_word,
            file_name="item_espejo.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True
        )
        
    with col_excel:
        archivo_excel = crear_excel(datos_obj)
        st.download_button(
            label="Descargar en Excel (.xlsx)",
            data=archivo_excel,
            file_name="item_espejo.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
